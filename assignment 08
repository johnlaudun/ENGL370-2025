{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21c4c1-8255-454f-9bac-e7d803da5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this notebook, I loaded only one text file and found all the adjectives and adverbs in it. Then I counted them and revelaed the 10 most common ones in each category.\n",
    "\n",
    "To start, I made sure the nltk library was available. This is a toolkit that helps Python understand and work with language. It can break up text into individual words by tokenizng and label each word with its part of speech I imported nltk at the beginning of my notebook so I could use its tools later in my code.\n",
    "# Add code cells step by step\n",
    "\n",
    "# Import necessary libraries\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Download necessary NLP models\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\"\"\"))\n",
    "\n",
    "# Load the text file\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Load text file\n",
    "with open('agnesofgod (2).txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Display first few characters\n",
    "print(text[:500])\n",
    "\"\"\"))\n",
    "\n",
    "# Tokenization and POS tagging\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Tokenization and POS tagging\n",
    "tokens = word_tokenize(text)\n",
    "tagged_words = pos_tag(tokens)\n",
    "\n",
    "# Show first 10 tagged words\n",
    "tagged_words[:10]\n",
    "\"\"\"))\n",
    "\n",
    "# Extract adjectives and adverbs\n",
    "\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "This piece of code helps me go through the first 100 words of my text and find all the adjectives. The text has already been processed so that each word is labeled with its part of speech like if it’s a noun, verb, or adjective. I used a loop to look at each word one at a time. For each word, I checked if its label was “JJ,” which is the code for adjectives. If it was, I used the word. This allowed me to quickly see which adjectives were used at the beginning of the text.\n",
    "# Extract adjectives (JJ, JJR, JJS) and adverbs (RB, RBR, RBS)\n",
    "adjectives = [word for word, tag in tagged_words if tag in ['JJ', 'JJR', 'JJS']]\n",
    "adverbs = [word for word, tag in tagged_words if tag in ['RB', 'RBR', 'RBS']]\n",
    "\n",
    "# Display counts\n",
    "print(f'Total Adjectives: {len(adjectives)}')\n",
    "print(f'Total Adverbs: {len(adverbs)}')\n",
    "\"\"\"))\n",
    "\n",
    "# Count and find top 10 most frequent adjectives and adverbs\n",
    "nb.cells.append(nbf.v4.new_code_cell(\"\"\"\n",
    "# Count occurrences\n",
    "adj_counts = Counter(adjectives)\n",
    "adv_counts = Counter(adverbs)\n",
    "\n",
    "# Get top 10 most frequent\n",
    "top_10_adj = adj_counts.most_common(10)\n",
    "top_10_adv = adv_counts.most_common(10)\n",
    "\n",
    "# Display results\n",
    "print('Top 10 Adjectives:', top_10_adj)\n",
    "print('Top 10 Adverbs:', top_10_adv)\n",
    "\"\"\"))\n",
    "\n",
    "# Save the notebook\n",
    "notebook_path = \"/mnt/data/Updated_08-bella.ipynb\"\n",
    "with open(notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "notebook_path\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4aaf72d-e525-4921-84fb-b32e83ce42c4",
   "metadata": {},
   "source": [
    "In this code, I used a function that helps me pull out specific kinds of words from my text. the function is called getPOS, which stands for get part of speech. When I use this function, I give it two things the type of word I want to find like nouns or proper nounds and the text I want to search through.\n",
    "\n",
    "Inside the function, the first thing I do is break the text into individual words Then, I label each word with its part of speech so now Python knows which words are nouns, verbs, adjectives,\n",
    "\n",
    "After that, I set up a loop to go through every word and its tag. If a word’s tag matches the one I asked for (like \"JJ\" for adjectives), I add that word to a list. Once it is done, the function gives me back a list of only the words that match the part of speech I was looking for.\n",
    "\n",
    "this function just makes my life easier to get the adjectives and nounds i want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0099a37-c68f-4db0-96ae-aa764b62aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def getPOS(POS, a_string):\n",
    "    tokens = nltk.word_tokenize(a_string)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    the_list = []\n",
    "    for i in tagged:\n",
    "        if i[1] == POS:\n",
    "            the_list.append(i[0])\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c79987b-91d7-4355-b545-68c5f1627c44",
   "metadata": {},
   "source": [
    "his is where the code gets important Now that I’ve got my getPOS() function, I start using it to find specific kinds of words in my text. First, I used the function to find all the adjectives by asking for the part-of-speech tag \"JJ\" Then I did the same thing to find all the adverbs, using the tag \"RB\". The results from both of these go into separate lists one called adjectives and the other called adverbs. After that, I used the len() function to count how many adjectives and how many adverbs were found, and I printed those numbers to see how many of each were used in the text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
