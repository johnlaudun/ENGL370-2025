{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52512eea-59da-412b-ae6d-0c28b7457a34",
   "metadata": {},
   "source": [
    "Cell 1: Import Libraries and Setup NLTK \n",
    "This cell is responsible for importing the necessary libraries and setting up NLTK. We use word_tokenize for tokenizing text, and pos_tag for labeling each word with its part of speech (POS). Counter helps us count the frequency of words later. The nltk.download commands ensure that we have the required language models available for POS tagging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b48eb-1afb-47a3-914b-818f7701d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "#  Setup: Ensure NLTK knows where to download data\n",
    "nltk.data.path.append(os.path.expanduser('~/nltk_data'))\n",
    "\n",
    "# Download required models (only needs to be run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5ba59-b4c9-491a-87f2-1431592caae6",
   "metadata": {},
   "source": [
    "Cell 2: Load and Preview the Text\n",
    "In this cell, we load the text from the file and preview a specific portion of the text (from index 15000 to 16000). This gives us an idea of how the text is structured and whether the loading process worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd51ae-d1d3-4b9a-a526-1d43bf281bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "with open(\"/Users/beauxcreel/code/ENGL370-2025/Creel/The_Science_of_Getting_Rich.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    tsogr = f.read()\n",
    "\n",
    "# Preview a portion of the raw text\n",
    "print(tsogr[15000:16000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11befddb-cdee-421b-a9a8-ab4e63779239",
   "metadata": {},
   "source": [
    " Cell 3: Normalize and Tokenize the Text\n",
    " This cell contains the tknize function, which helps prepare the text for analysis. It removes unwanted characters (like punctuation, except for periods), converts the text to lowercase, and then tokenizes it into individual words. Tokenizing means breaking the text down into smaller pieces (tokens), which will help in identifying and analyzing different parts of speech (POS) later on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0121d992-f9cc-4db0-85b1-6d35607eba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tokenizer: remove punctuation (except periods) and lowercase all words\n",
    "def tknize(a_string):\n",
    "    clean = re.sub(r'[^a-zA-Z \\.]', ' ', a_string).lower()\n",
    "    return word_tokenize(clean)\n",
    "\n",
    "# Tokenize the text\n",
    "tsogr_tokens = tknize(tsogr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98057c7a-eb21-4b33-83db-f72b36686b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cell 4: POS Tag the Entire Text\n",
    "Now that the text is tokenized, we use pos_tag to assign a part of speech\n",
    "(POS) tag to each token. This means that every word in the tokenized text\n",
    "will be labeled with a tag like \"NN\" (noun), \"VB\" (verb), or \"JJ\" (adjective). \n",
    "This step is crucial for identifying specific parts of speech such as adjectives\n",
    "and adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ebc834-a5ee-4daf-ab69-f942d4b548a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag each token with its part of speech (POS)\n",
    "tsogr_tagged = pos_tag(tsogr_tokens, lang='eng')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73fbb3b-cbc9-49d8-95cc-556df66b71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cell 5: Slice a Section and Extract Adjectives/Adverbs\n",
    "In this cell, we slice the text to focus on a section between the indices 15000 and 16000, giving us a smaller sample. \n",
    "We then extract the adverbs (tagged as \"RB\") and adjectives (tagged as \"JJ\") from this section usinglist comprehensions. \n",
    "For each word, we check if its POS tag matches \"RB\" for adverbs or \"JJ\" for adjectives. After extracting the words, we print the \n",
    "adverbs and adjectives found in this section and display the total counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d83f9f-e5b4-49fc-b6c5-864b7d2377b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adverbs in slice: ['so', 'all', 'so', 'away', 'there', 'so', 'not', 'yet', 'up', 'so', 'so', 'so', 'together', 'there', 'together', 'about', 'as', 'so', 'then', 'long', 'so', 'up', 'so', 'alone', 'very', 'still', 'not', 'either', 'therefore', 'quite', 'there', 'up', 'so', 'so', 'so', 'dully', 'up', 'again', 'together', 'so', 'heartily', 'so', 'then', 'so', 'nd', 'so', 'up', 'never', 'so', 'only', 'also', 'well', 'not', 'not', 'i', 'so', 'almost', 'afeard', 'more', 'up', 'here', 'up', 'again']\n",
      "Adjectives in slice: ['unlikely', 'cold', 'great', 'mr.', 'leigh', 'i', 'sir', 'petty', 's', 'little', 'displeased', 'poor', 'troubled', 'lonely', 'great', 'full', 'mr.', 's', 'great', 'friendly', 'white', 'tangier', 'many', 'little', 'good', 'matted', 'late', 'first', 'worth', 'next', 'much', 'worth', 'i', 'good', 'monday', 'next', 'lord', 's', 'pleasant', 'i', 'fit', 'white', 'queen', 's', 'mr.', 'great', 'good', 'simple', 'lord', 'weary', 'last', 'cold', 'spent', 'past', 'o', 'good', 'osborne', 'much', 'ready', 'many', 'married', 'late', 'great', 'strange', 'i', 'ready', 'white', 'feared', 'mr.', 'brave', 's', 'many', 'new', 'great', 'good']\n",
      "\n",
      "Total adverbs: 63, Total adjectives: 75\n",
      "\n",
      "Reconstructed text slice:\n",
      "unlikely place . it being cold mr. lee and i did sit all the day till three o clock by the fire in the governor s house i reading a play of fletcher s being a wife for a month wherein no great wit or language . having done we went to them at work and having wrought below the bottom of the foundation of the wall i bid them give over and so all our hopes ended and so went home taking mr. leigh with me and after drunk a cup of wine he went away and i to my office there reading in sir w. petty s book and so home and to bed a little displeased with my wife who poor wretch is troubled with her lonely life which i know not how without great charge to help as yet but i will study how to do it . th . up and had l brought me by prior of brampton in full of his purchase money for barton s house and some land . so to the office and thence with mr. coventry in his coach to st. james s with great content and pride to see him treat me so friendly and dined with him and so to white hall together where we met upon the tangier commission and discoursed many things thereon but little will be done before my lord rutherford comes there as to the fortification or mole . that done my lord sandwich and i walked together a good while in the matted gallery he acquainting me with his late enquiries into the wardrobe business to his content and tells me how things stand . and that the first year was worth about l to him and the next about as much so that at this day if he were paid it will be worth about l to him . but it contents me above all things to see him trust me as his confidant so i bid him good night he being to go into the country to keep his christmas on monday next . so by coach home and to my office being post night and then home and to bed . st lord s day . lay long in bed so up to church and so home to dinner alone with my wife very pleasant . after dinner i walked to my brother s where he told me some hopes he had of bringing his business to pass still of his mistress but i do find they do stand upon terms that will not be either fit or in his power to grant and therefore i did dislike his talk and advised him to give it quite over . thence walked to white hall and there to chappell and from thence up stairs and up and down the house and gallerys on the king s and queen s side and so through the garden to my lord s lodgings where there was mr. gibbons madge and mallard and pagett and by and by comes in my lord sandwich and so we had great store of good musique . by and by comes in my simple lord chandois who my lord sandwich being gone out to court began to sing psalms but so dully that i was weary of it . at last we broke up and by and by comes in my lord sandwich again and he and i to talk together about his businesses and so he to bed and i and mr. creed and captain ferrers fell to a cold goose pye of mrs. sarah s heartily and so spent our time till past twelve o clock and then with creed to his lodgings and so with him to bed and slept till nd . six or seven o clock and so up and by the fireside read a good part of the advice to a daughter which a simple coxcomb has wrote against osborne but in all my life i never did nor can expect to see so much nonsense in print thence to my lord s who is getting himself ready for his journey to hinchingbroke . and by and by after eating something and talking with me about many things and telling me his mind upon my asking about sarah who it seems only married of late but is also said to be turned a great drunkard which i am ashamed of that he likes her service well and do not love a strange face but will not endure the fault but hath bade me speak to her and advise her if she hath a mind to stay with him which i will do . my lord and his people being gone i walked to mr. coventry s chamber where i found him gone out into the park with the duke so the boy being there ready with my things i shifted myself into a riding habitt and followed him through white hall and in the park mr. coventry s people having a horse ready for me so fine a one that i was almost afeard to get upon him but i did and found myself more feared than hurt and i got up and followed the duke who with some of his people among others mr. coventry was riding out . and with them to hide park . where mr. coventry asking leave of the duke he bid us go to woolwich . so he and i to the waterside and our horses coming by the ferry we by oars over to lambeth and from thence with brave discourse by the way rode to woolwich where we eat and drank at mr. peat s and discoursed of many businesses and put in practice my new way of the call book which will be of great use . here having staid a good while we got up again and brought night home with us\n"
     ]
    }
   ],
   "source": [
    "#  Slice a section from index 15000 to 16000\n",
    "tagged_slice = tsogr_tagged[15000:16000]\n",
    "\n",
    "# Find adverbs and adjectives in that slice\n",
    "adverbs = [word for word, tag in tagged_slice if tag.startswith(\"RB\")]\n",
    "adjectives = [word for word, tag in tagged_slice if tag.startswith(\"JJ\")]\n",
    "\n",
    "# Display results\n",
    "print(\"Adverbs in slice:\", adverbs)\n",
    "print(\"Adjectives in slice:\", adjectives)\n",
    "print(f\"\\nTotal adverbs: {len(adverbs)}, Total adjectives: {len(adjectives)}\")\n",
    "\n",
    "# Show original sentence fragment\n",
    "reconstructed = \" \".join([word for word, tag in tagged_slice])\n",
    "print(\"\\nReconstructed text slice:\")\n",
    "print(reconstructed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e31ad-43e6-4b7d-acc5-7c9d5e8ace22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cell 6: Count Top 10 Adverbs and Adjectives in the Entire Text (end of assignement)\n",
    "This final cell processes the entire text to count the frequency of each adjective and adverb. \n",
    "It extracts all the words that are tagged as adverbs (RB) and adjectives (JJ). \n",
    "After collecting the words, we use Counter to count how often each word appears. \n",
    "Finally, we print the top 10 most frequent adjectives and adverbs in the entire text. \n",
    "This allows us to identify which words are most commonly used in each category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4c0f1c-7097-4a11-901f-9c9bb795ed2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Adverbs in Entire Text:\n",
      "[('so', 482), ('not', 298), ('very', 190), ('then', 148), ('up', 108), ('well', 100), ('now', 90), ('again', 80), ('there', 76), ('here', 52)]\n",
      "\n",
      "Top 10 Adjectives in Entire Text:\n",
      "[('i', 216), ('great', 198), ('good', 154), ('other', 134), ('s', 118), ('mr.', 94), ('sir', 80), ('little', 66), ('much', 58), ('electronic', 54)]\n"
     ]
    }
   ],
   "source": [
    "# Frequency Counts for Entire Text\n",
    "# Extract all adverbs and adjectives from full tagged text\n",
    "all_adverbs = [word for word, tag in tsogr_tagged if tag.startswith(\"RB\")]\n",
    "all_adjectives = [word for word, tag in tsogr_tagged if tag.startswith(\"JJ\")]\n",
    "\n",
    "# Count most common using Counter\n",
    "adverb_counts = Counter(all_adverbs)\n",
    "adjective_counts = Counter(all_adjectives)\n",
    "\n",
    "# Display top 10 of each\n",
    "print(\"\\nTop 10 Adverbs in Entire Text:\")\n",
    "print(adverb_counts.most_common(10))\n",
    "\n",
    "print(\"\\nTop 10 Adjectives in Entire Text:\")\n",
    "print(adjective_counts.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e178a-6aa7-4fee-8bad-ee026ad0dbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
