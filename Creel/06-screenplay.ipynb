{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84267f11-5904-415f-bd5e-fa8a6ffde343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65931e8f-061a-4390-b3cc-cc663da58b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/beauxcreel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/beauxcreel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 screenplays.\n",
      "Loaded screenplays: ['aladdin.txt', 'princessbridethe.txt', 'findingnemo.txt', 'kungfupanda.txt', 'e.t..txt']\n",
      "\n",
      "Preview of aladdin.txt:\n",
      "\n",
      "ALADDIN:  THE COMPLETE SCRIPT\n",
      "\n",
      "COMPILED BY BEN SCRIPPS \n",
      "\n",
      "(Portions Copyright (c) 1992 The Walt Disney Company\n",
      "\n",
      "PEDDLER:    Oh I come from a land\n",
      "\n",
      "    From a faraway place\n",
      "\n",
      "    Where the caravan camels roam\n",
      "\n",
      "    Where they cut off your ear /Where it's flat and immense\n",
      "\n",
      "    If they don't like your face /And the heat is intense\n",
      "\n",
      "    It's barbaric, but hey--it's home!\n",
      "\n",
      "    When the wind's at your back\n",
      "\n",
      "    And the sun's from the west\n",
      "\n",
      "    And the sand in the glass is right\n",
      "\n",
      "    Come on down,\n",
      "\n",
      "    St\n",
      "\n",
      "Cleaned Preview of aladdin.txt:\n",
      "\n",
      "aladdin complete script compiled ben scripps portions copyright c 1992 walt disney company peddler oh come land faraway place caravan camels roam cut ear flat immense dont like face heat intense barbaric heyits home winds back suns west sand glass right come stop hop carpet fly another arabian night arabian nights like arabian days often hotter hot lot good ways arabian nights neath arabian moons fool guard could fall fall hard dunes ah salaam good evening worthy friend please please come closer\n",
      "                      10  100  101  102  103  104  105  106  106a  107  ...  \\\n",
      "aladdin.txt            0    0    0    0    0    0    0    0     0    0  ...   \n",
      "princessbridethe.txt   1    1    1    1    1    1    1    1     0    1  ...   \n",
      "findingnemo.txt        1    1    0    0    0    0    0    1     1    1  ...   \n",
      "kungfupanda.txt        1    0    0    0    0    0    0    0     0    0  ...   \n",
      "e.t..txt               0    0    0    0    0    0    0    0     0    0  ...   \n",
      "\n",
      "                      zero  zeroed  zings  zip  zips  zombie  zones  zoo  \\\n",
      "aladdin.txt              0       0      1    0     1       1      0    1   \n",
      "princessbridethe.txt     0       1      0    0     0       0      0    0   \n",
      "findingnemo.txt          0       0      0    0     0       0      4    1   \n",
      "kungfupanda.txt          4       0      0    0     0       0      0    0   \n",
      "e.t..txt                 0       0      0    1     2       0      0    0   \n",
      "\n",
      "                      zoom  zooms  \n",
      "aladdin.txt              4      8  \n",
      "princessbridethe.txt     0      1  \n",
      "findingnemo.txt          0      0  \n",
      "kungfupanda.txt          1      0  \n",
      "e.t..txt                 0      0  \n",
      "\n",
      "[5 rows x 7402 columns]\n",
      "Document-Term Matrix saved as 'screenplays_dtm.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# First, let's download the required NLTK resources if they aren't already downloaded.\n",
    "# The 'punkt' tokenizer helps break the text into individual words,\n",
    "# and 'stopwords' helps us remove common words like 'the', 'a', etc. that don't add much meaning.\n",
    "nltk.download('punkt')  # Download Punkt Tokenizer\n",
    "nltk.download('stopwords')  # Download Stopwords\n",
    "\n",
    "# Define the folder path where the \"family.\" folder is located\n",
    "# Make sure the path matches where you have stored your text files.\n",
    "folder_path = \"/Users/beauxcreel/code/ENGL370-2025/Creel/family.\"\n",
    "\n",
    "# List all the .txt files in the \"family.\" folder, assuming all screenplays are in .txt format.\n",
    "screenplay_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# I'm limiting the number of screenplays we load for now, so we don’t overwhelm ourselves.\n",
    "MAX_FILES = 5  # We can adjust this to load more or fewer files.\n",
    "\n",
    "# Now, let's load the screenplays. We'll read the first MAX_FILES files from the \"family.\" folder.\n",
    "# This allows us to focus on a smaller sample, which is easier to manage.\n",
    "screenplays = {}\n",
    "for file in screenplay_files[:MAX_FILES]:\n",
    "    with open(os.path.join(folder_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        # Store the screenplay title and content as a key-value pair in the dictionary\n",
    "        screenplays[file] = f.read()\n",
    "\n",
    "# Let's confirm that we've successfully loaded the screenplays.\n",
    "# We’ll print the number of screenplays and the names of the ones we loaded.\n",
    "print(f\"Loaded {len(screenplays)} screenplays.\")  # Output how many screenplays we’ve loaded.\n",
    "print(\"Loaded screenplays:\", list(screenplays.keys()))  # Output the list of loaded filenames.\n",
    "\n",
    "# Let's preview the content of one screenplay to ensure it's been loaded correctly.\n",
    "sample_script = list(screenplays.keys())[0]  # Pick the first screenplay from the list\n",
    "print(f\"\\nPreview of {sample_script}:\\n\")\n",
    "print(screenplays[sample_script][:500])  # Print the first 500 characters of the first screenplay\n",
    "\n",
    "# Now, let's clean and preprocess the text. The goal here is to make the text easier to analyze.\n",
    "# We’ll remove unnecessary punctuation, convert everything to lowercase, and eliminate common stopwords (like 'the', 'a', etc.)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert the text to lowercase to make it case-insensitive\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation (anything that's not a word or space)\n",
    "    tokens = word_tokenize(text)  # Tokenize the text into words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return ' '.join(tokens)  # Join the words back into a string after cleaning\n",
    "\n",
    "# We apply the preprocessing function to all the screenplays we've loaded.\n",
    "# This will clean up the text, making it ready for further analysis.\n",
    "cleaned_screenplays = {title: preprocess_text(text) for title, text in screenplays.items()}\n",
    "\n",
    "# Let's print out a preview of the cleaned text to make sure everything looks good.\n",
    "sample_script = list(cleaned_screenplays.keys())[0]  # Again, pick the first screenplay\n",
    "print(f\"\\nCleaned Preview of {sample_script}:\\n\")\n",
    "print(cleaned_screenplays[sample_script][:500])  # Show the first 500 characters of the cleaned text\n",
    "\n",
    "# Now that our text is cleaned and ready, it's time to convert it into a Document-Term Matrix (DTM).\n",
    "# The DTM is a matrix where rows represent the screenplays and columns represent the unique words in all the screenplays.\n",
    "# The values in the matrix represent the frequency of each word in each screenplay.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize CountVectorizer: this tool will help us convert the text into a matrix of word counts.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Use the vectorizer to transform the cleaned screenplays into a Document-Term Matrix (DTM).\n",
    "# The 'fit_transform' method creates the matrix based on the cleaned text.\n",
    "dtm = vectorizer.fit_transform(cleaned_screenplays.values())\n",
    "\n",
    "# Convert the DTM to a pandas DataFrame for easier readability.\n",
    "# The rows are the titles of the screenplays, and the columns are the unique words (features).\n",
    "dtm_df = pd.DataFrame(dtm.toarray(), index=cleaned_screenplays.keys(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Let's display the first few rows of the DTM so we can see the structure.\n",
    "print(dtm_df.head())  # Output the first few rows of the Document-Term Matrix.\n",
    "\n",
    "# Now, let's save the DTM as a CSV file.\n",
    "# This will allow us to easily access the DTM later or use it in further analysis.\n",
    "dtm_df.to_csv(\"screenplays_dtm.csv\")\n",
    "\n",
    "print(\"Document-Term Matrix saved as 'screenplays_dtm.csv'.\")  # Confirm that the CSV file was saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee5ad8-68db-4090-af2c-46e7f8314e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
