{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb420e0a-c2e8-4fbe-98b4-21f7cec84317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT I\n",
      "SCENE I. An open Place.\n",
      "Thunder and Lightning. Enter three Witches.\n",
      "\n",
      "FIRST WITCH.\n",
      "When shall we three meet again?\n",
      "In thunder, lightning, or in rain?\n",
      "\n",
      "SECOND WITCH.\n",
      "When the hurlyburly’s done,\n",
      "When the battle’s lost and won.\n",
      "\n",
      "THIRD WITCH.\n",
      "That will be ere the set of sun.\n",
      "\n",
      "FIRST WITCH.\n",
      "Where the place?\n",
      "\n",
      "SECOND WITCH.\n",
      "Upon the heath.\n",
      "\n",
      "THIRD WITCH.\n",
      "There to meet with Macbeth.\n",
      "\n",
      "FIRST WITCH.\n",
      "I come, Graymalkin!\n",
      "\n",
      "SECOND WITCH.\n",
      "Paddock calls.\n",
      "\n",
      "THIRD WITCH.\n",
      "Anon.\n",
      "\n",
      "ALL.\n",
      "Fair is foul, and foul is fai\n"
     ]
    }
   ],
   "source": [
    "# Open and read the text file\n",
    "with open(\"Macbeth.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    macbeth_text = file.read()\n",
    "\n",
    "# Print the first 500 characters to check if it loaded correctly\n",
    "print(macbeth_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c11cdcd-156f-418f-a91c-889a34f24fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACT', 'I', 'SCENE', 'I', '.', 'An', 'open', 'Place', '.', 'Thunder', 'and', 'Lightning', '.', 'Enter', 'three', 'Witches', '.', 'FIRST', 'WITCH', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(macbeth_text)\n",
    "\n",
    "# Print the first 20 words as a preview\n",
    "print(words[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4948e4b2-2abf-4b32-86a0-1a9d0080ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACT I\\nSCENE I.', 'An open Place.', 'Thunder and Lightning.', 'Enter three Witches.', 'FIRST WITCH.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into sentences\n",
    "sentences = nltk.sent_tokenize(macbeth_text)\n",
    "\n",
    "# Print the first 5 sentences as a preview\n",
    "print(sentences[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6181a6b8-7865-41bb-924e-f9c406cf6db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 65), (',', 63), ('’', 28), ('the', 24), ('d', 14), ('to', 12), ('and', 11), ('of', 11), ('his', 11), ('WITCH', 9)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count word frequencies\n",
    "word_frequencies = Counter(words)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(word_frequencies.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bf051a0-5323-4be8-b910-5c9ca5e90303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('’', 28), ('witch', 9), ('duncan', 9), ('king', 6), ('ross', 6), ('macbeth', 5), ('upon', 4), ('soldier', 4), ('worthy', 4), ('till', 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bellabossier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Define stopwords and punctuation\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Remove stopwords and punctuation from the tokenized words\n",
    "cleaned_words = [word.lower() for word in words if word.lower() not in stop_words and word not in punctuation]\n",
    "\n",
    "# Count word frequencies again after cleaning\n",
    "cleaned_word_frequencies = Counter(cleaned_words)\n",
    "\n",
    "# Print the 10 most common words after cleaning\n",
    "print(cleaned_word_frequencies.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ed847-75f6-4be4-8ea3-5d7257a5a200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
