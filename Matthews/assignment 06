import os
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
import matplotlib.pyplot as plt
import seaborn as sns

# Load screenplay files
file_paths = [
    'agnesofgod (1).txt',
    'afewgoodmen (1).txt',
    '8mm (1).txt'
]

screenplays = {}
for path in file_paths:
    with open(path, 'r', encoding='utf-8') as file:
        screenplays[os.path.basename(path)] = file.read()

documents = list(screenplays.values())
titles = [os.path.splitext(os.path.basename(path))[0] for path in file_paths]  # Extracting screenplay titles

# Experiment with different min_df and max_df values
min_df_values = [1, 2, 3]
max_df_values = [0.7, 0.8, 0.9]

best_dtm = None
best_params = None

for min_df in min_df_values:
    for max_df in max_df_values:
        vectorizer = CountVectorizer(min_df=min_df, max_df=max_df, stop_words='english')
        X = vectorizer.fit_transform(documents)
        dtm = pd.DataFrame(X.toarray(), index=titles, columns=vectorizer.get_feature_names_out())
        
        if best_dtm is None or len(dtm.columns) > len(best_dtm.columns):
            best_dtm = dtm
            best_params = (min_df, max_df)

# Display chosen parameters
print(f"Best parameters chosen: min_df={best_params[0]}, max_df={best_params[1]}")

# Display sample of best DTM
display(best_dtm.head())

# Save best DTM to CSV with screenplay titles as row labels
output_file = "document_term_matrix.csv"
best_dtm.to_csv(output_file, index=True)

print(f"Document-Term Matrix successfully created and saved as '{output_file}'.")

# Visualizing word frequency
word_counts = np.asarray(best_dtm.sum(axis=0)).flatten()
word_freq = pd.DataFrame({'word': best_dtm.columns, 'count': word_counts})
word_freq = word_freq.sort_values(by='count', ascending=False).head(20)

plt.figure(figsize=(10,5))
sns.barplot(x='count', y='word', data=word_freq, palette='viridis')
plt.title('Top 20 Most Frequent Words')
