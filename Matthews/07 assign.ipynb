{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b6793-08ff-4fce-8c4c-832571baa7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4f040-cb01-4405-8c77-cf8d3437209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c08d3-0e8c-497d-80bf-9ed8bde0a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus is pointing to my comedy text\n",
    "path_to_corpus = \\Users\\Matthews\\code\\ENGL370-2025\\ENGL370-2025\\\\Data\\mystery'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451fa13-0cc0-4bd3-bb89-6f231511f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all my documents that is in my corpus\n",
    "documents = [open(file, 'r', encoding='utf-8').read() for file in glob.glob(os.path.join(path_to_corpus, '*.txt'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5580a-1836-4515-bfee-a35c8e0eb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give me the LDA Topics but not reading them\n",
    "vectorizer_lda = CountVectorizer(stop_words='english')\n",
    "dtm_lda = vectorizer_lda.fit_transform(documents)\n",
    "lda = LatentDirichletAllocation(n_components=4, random_state=42)\n",
    "lda.fit(dtm_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5089a-fc35-4efd-a04c-e231694e0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read me the lDA topics\n",
    "print(\"LDA Topics:\")\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    print(\" \".join([vectorizer_lda.get_feature_names_out()[i] for i in topic.argsort()[:-6 - 1:-1]]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc0234-3828-4c56-a1aa-5abf52de4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give me the NMF information\n",
    "vectorizer_nmf = TfidfVectorizer(stop_words='english')\n",
    "dtm_nmf = vectorizer_nmf.fit_transform(documents)\n",
    "nmf = NMF(n_components=4, random_state=42)\n",
    "nmf.fit(dtm_nmf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d6235-abce-4bdb-90db-cb0c7b8e3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display NMF topics\n",
    "print(\"NMF Topics:\")\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    print(\" \".join([vectorizer_nmf.get_feature_names_out()[i] for i in topic.argsort()[:-6 - 1:-1]]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098b3b8-b189-4182-a33f-179e85660d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
LDA Topics: Topic 1: don int just know like day

Topic 2: int don just know like looks

Topic 3: just don int like know day

Topic 4: just int don like know day

NMF Topics: Topic 1: int just continued don like know

Topic 2: ted elaine healy lori john paul

Topic 3: adam emma jacob seth nick eve

Topic 4: rick fred elijah melanie debbie maggie
First I loaded the data from my comedy library. Both in LDA and NMF topics. The LDA gave me broad topics that is hard to understand. LDA is good to work with my larger documents. Which is good for my comedies. It recongnizes words that act together. The nmf analyzes rare words and breaks the text down into smaller bits. I found that this work better and analyzed my comedies better even though the topic is still the same. It picked up more names than anything.

Click to add a cell.
