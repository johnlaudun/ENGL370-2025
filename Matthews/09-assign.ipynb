{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cd25dd82-431a-4f4f-a4f2-11cf1a664b83",
   "metadata": {},
   "source": [
    "First step was to load all my romance files so I got all my .txt files in my folder in my folder. These are all the texts of the romance novels I used python pathlib to load them which is good for handling a bunch of files this was the easiest part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82329a3-7151-44cd-aa48-faab707e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Use the current directory (since the notebook and .txt files are in the same folder)\n",
    "romance_folder = Path(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd13f63-5c07-4558-99c9-1850f79f48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all .txt files in the folder\n",
    "romance_files = list(romance_folder.glob(\"*.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97650b-f9bb-40b0-af41-8844cdfcdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the content of all romance text files into a dictionary\n",
    "romance_texts = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fab88a-9f21-4caf-8335-f4ec70f36b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in romance_files:\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        romance_texts[file_path.name] = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046fce9-45d4-48c4-af85-312ac4c3b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(f\"Loaded {len(romance_texts)} files:\")\n",
    "for name in romance_texts:\n",
    "    print(\"-\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf0554-8e1c-4b89-9465-59e144a92c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loaded 193 files:\n",
    "8mm.txt\n",
    "afewgoodmen.txt\n",
    "angleldemons.txt\n",
    "aprilfoosday.txt\n",
    "avventuralheaderture.txt\n",
    "backdraft.txt\n",
    "basic.txt\n",
    "basicinistint.txt\n",
    "biblebowkitch.txt\n",
    "blackevelevt.txt\n",
    "boundrieidenitythe.txt\n",
    "bourneultimathe.txt\n",
    "boxth.txt\n",
    "brick,txt\n",
    "buried.txt\n",
    "case39.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e291c8f-2287-444c-8382-43c414c40554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load romance texts\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('mystery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f5e4d-e9f6-4b24-ac98-7dff77e60772",
   "metadata": {},
   "outputs": [],
   "source": [
    "romance_folder = Path(\".\")\n",
    "romance_files = list(romance_folder.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2e0b3-e5a1-407e-9601-a67a620dc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "romance_texts = {}\n",
    "for file_path in romance_files:\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        romance_texts[file_path.name] = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782eb1d-8aa7-41c6-9384-ee25abe666b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tokenize\n",
    "tokenized_texts = {}\n",
    "for filename, text in romance_texts.items():\n",
    "    tokens = word_tokenize(text)\n",
    "    tokenized_texts[filename] = tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980d148-1238-405f-95ce-79f1e02014af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove proper nouns\n",
    "cleaned_texts = {\n",
    "    filename: [\n",
    "        word for word, tag in pos_tag(tokens)\n",
    "        if tag not in ('NNP', 'NNPS')\n",
    "    ]\n",
    "    for filename, tokens in tokenized_texts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c96778-1fd9-4f12-8320-806d7f0b8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: TF-IDF VECTORIZE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.9,\n",
    "    min_df=5,\n",
    "    stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167d53d1-4800-486a-9012-6f712d47cfac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mtokenized_texts\u001b[49m\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(joined_cleaned_texts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msomefilename.txt\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m100\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_texts' is not defined"
     ]
    }
   ],
   "source": [
    "print(list(tokenized_texts.items())[:1])\n",
    "print(joined_cleaned_texts['somefilename.txt'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd27dd8-bb7c-4879-bea6-0c4eba661850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
