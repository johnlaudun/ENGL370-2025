{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15525d9f-d094-4958-8fbb-eecc09634573",
   "metadata": {},
   "source": [
    "In this notebook, I loaded only one text file and found all the adjectives and adverbs in it. Then I counted them and revelaed the 10 most common ones in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79cdd5-606f-4106-946c-21829ea1f773",
   "metadata": {},
   "source": [
    "To start, I made sure the nltk library was available. This is a toolkit that helps Python understand and work with language. It can break up text into individual words by tokenizng and label each word with its part of speech I imported nltk at the beginning of my notebook so I could use its tools later in my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d568f7-ee0b-48cc-a371-df231649d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def tknize(a_string):\n",
    "    clean = re.sub('[^a-zA-Z \\.]', ' ', a_string).lower()\n",
    "    return nltk.tokenize.word_tokenize(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ffdbe-8390-47e8-8267-b6fb5b84f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "with open(\"8mm.txt\",mode=\"r\", encoding=\"utf-8\") as f: 8mm= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9b442-eb32-4b4f-9f0b-3518b22cff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 50 tokens\n",
    "tokens = tknize(8mm [:1000]) # or 8mm if you want the whole thing\n",
    "print(tokens{:50})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228be77-d7dc-4109-9454-f9ca754157d9",
   "metadata": {},
   "source": [
    "'by', 'scott', 'neustadter', 'michael', 'h.', 'weber', 'first', 'draft', 'simple', 'black', 'on', 'white', 'credits', 'roll', 'to', 'big', 'star', 's', 'i', 'm', 'in', 'love', 'with', 'a', 'girl', '.', 'when', 'all', 'is', 'said', 'and', 'done', 'up', 'comes', 'a', 'single', 'number', 'in', 'parenthesis', 'like', 'so', 'ext', '.', 'park', 'day', 'for']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe802660-28a2-4dea-b8e2-44a9e37d6cee",
   "metadata": {},
   "source": [
    "This piece of code helps me go through the first 100 words of my text and find all the adjectives. The text has already been processed so that each word is labeled with its part of speech like if it’s a noun, verb, or adjective. I used a loop to look at each word one at a time. For each word, I checked if its label was “JJ,” which is the code for adjectives. If it was, I used the word. This allowed me to quickly see which adjectives were used at the beginning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79369295-bd62-44e1-aba0-210e054476f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print adjectives from first 100 tokens\n",
    "for t in agnesofgod.txt[0:100]:\n",
    "    if t[1] == 'JJ':\n",
    "     print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e28c1-7f2f-499a-887b-efd307c7330b",
   "metadata": {},
   "source": [
    " [('She', 'PRP'), ('is', 'VBZ'), ('beautiful', 'JJ'), ('and', 'CC'), ('kind', 'JJ')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5f3f0-a457-4ef2-9276-f3569db09fba",
   "metadata": {},
   "source": [
    "I started by importing the nltk library, which helps me break up the text and figure out what kind of word each one is. Then I defined a function called getPOS() that lets me pick a part of speech like nouns and adjectives and search for just those in the text. Inside the function, I first break the text into words, then label each one with its part of speech. I go through all the words and if the tag matches the one I’m looking for but for this one I am looking for nouns which is NN, I save that word in a list. After running the function, I called it with \"NN\" to find all the nouns in my text and then printed the list to see the results. and got every single noun and it was a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe750b-f0c4-4b2e-b76b-877e9c47af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def getPOS(POS, a_string):\n",
    "    tokens = nltk.word_tokenize(a_string)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    the_list = []\n",
    "    for i in tagged:\n",
    "        if i[1] == POS:\n",
    "            the_list.append(i[0])\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6f970-601f-45ac-9477-8c058efe5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = getPOS(\"NN\", 8mm.txt)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ab007-e200-4fdc-b683-8430b8d5b9fc",
   "metadata": {},
   "source": [
    "camera, car, capital, cellular, cindy, city, clothing, college, company, copy, crib, crickets, crowd, curbside, dairy, day, desk, detective, discotheque, documents, door, driver, driveway, evidence, family, file, files, film, flag, floor, food, ford, friend, front, funeral, gate, girl, gold, gun, hair, hallway, harrisburg, hello, highway, hotel, house, information, invoice, job, kitchen, lawyer, letters, library, light, limo, living, lock, lodge, lot, luggage, man, mansion, map, miami, millimeter, mirror, money, motel, motor, movement, murder, music, neighbor, night, notepad, office, official, pants, paper, passengers, pennsylvania, person, phone, photo, photos, plan, pleasure, police, politician, porch, poster, projector, property, restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72a97e-1278-46c1-8c1b-fce87c2362a1",
   "metadata": {},
   "source": [
    "In this code, I used a function that helps me pull out specific kinds of words from my text. the function is called getPOS, which stands for get part of speech. When I use this function, I give it two things the type of word I want to find like nouns or proper nounds and the text I want to search through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f303911-75b1-4074-bf91-eb4efe9138c8",
   "metadata": {},
   "source": [
    "Inside the function, the first thing I do is break the text into individual words Then, I label each word with its part of speech so now Python knows which words are nouns, verbs, adjectives,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19aaea-6181-46a6-9e6b-61f75285e895",
   "metadata": {},
   "source": [
    "After that, I set up a loop to go through every word and its tag. If a word’s tag matches the one I asked for (like \"JJ\" for adjectives), I add that word to a list. Once it is done, the function gives me back a list of only the words that match the part of speech I was looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90d30a-7c3b-4ca7-bd23-cc57d1fb06b4",
   "metadata": {},
   "source": [
    "this function just makes my life easier to get the adjectives and nounds i want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75619a-00fa-49f1-b42b-52faf2981d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def getPOS(POS, a_string):\n",
    "    tokens = nltk.word_tokenize(a_string)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    the_list = []\n",
    "    for i in tagged:\n",
    "        if i[1] == POS:\n",
    "            the_list.append(i[0])\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5220a6e-f54c-4a5e-a686-b58e65d96a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"8mm.txt mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    summer = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e71889-39f2-424e-a496-1e271c66a0b2",
   "metadata": {},
   "source": [
    "this is where the code gets important Now that I’ve got my getPOS() function, I start using it to find specific kinds of words in my text. First, I used the function to find all the adjectives by asking for the part-of-speech tag \"JJ\" Then I did the same thing to find all the adverbs, using the tag \"RB\". The results from both of these go into separate lists one called adjectives and the other called adverbs. After that, I used the len() function to count how many adjectives and how many adverbs were found, and I printed those numbers to see how many of each were used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537149ad-b54e-4fb0-96c9-0a466384cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all adjectives\n",
    "adjectives = getPOS\"jj\",8mm.txtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73ff51-5180-4a40-bcf8-4c4b8035872e",
   "metadata": {},
   "outputs": [],
   "source": [
    " Print how many of each\n",
    "print(\"Number of adjectives:\", len(adjectives))\n",
    "print(\"Number of adverbs:\", len(adverbs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e33d2a-029a-420a-88fb-604f8995ce0f",
   "metadata": {},
   "source": [
    "number of adjctives:1,772\n",
    "\n",
    "number of adverbs:198\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf63da-f222-40a3-930b-c8aae43f9ecb",
   "metadata": {},
   "source": [
    "now that I have lists of all the adjectives and adverbs in my text, I need to find out which ones were used the most. chatgpt gave me this code and i had to look up what it meant I used this Python tool called Counter from the collections module, which is pretty handy. It goes through a list and counts how many times each word shows up. I ran it on my lists of adjectives and adverbs. Then, I called the .most_common(10) method to grab the top 10 words from each list—basically the most frequently used adjectives and adverbs in the whole text. In the end, I printed both lists to see which words were popping up the most in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d8357-d8f0-413b-af2f-b85712f03fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get top 10 adjectives\n",
    "top_adjectives = Counter(adjectives).most_common(10)\n",
    "\n",
    "# Get top 10 adverbs\n",
    "top_adverbs = Counter(adverbs).most_common(10)\n",
    "\n",
    "print(\"Top 10 Adjectives:\")\n",
    "print(top_adjectives)\n",
    "\n",
    "print(\"\\nTop 10 Adverbs:\")\n",
    "print(top_adverbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497e44a-255b-4e96-8198-cb9a1eff6f54",
   "metadata": {},
   "source": [
    "top 10 adjectives: [('day', 170), ('amy', 103), ('they', 80), ('by', 62), ('mary', 55), ('my', 50), ('away', 49), ('table', 45), ('cindy', 36), ('way', 30)]\n",
    "\n",
    "top 10 adverbs: [('only', 24), ('slowly', 15), ('exactly', 9), ('finally', 9), ('probably', 8), ('really', 8), ('mostly', 6), ('certainly', 5), ('carefully', 5), ('suddenly', 5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9480af5c-0164-4390-8c95-9b31dea9e283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
